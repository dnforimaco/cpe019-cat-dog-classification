# -*- coding: utf-8 -*-
"""Cat-Dog_Classification-[TRAININGMODEL]

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SBqKE_c19RsPNM9Xa--pw8nWh1Y8UjbT

**T3-CPE32S1-CPE019 Members:**

Orimaco, Dirk Nash F.

Carale, Alyzza R.

Alipio, John Rafael S.

Apit, Regine Louise T.

Mendoza, Khlowee A.

Dataset: Cats and Dogs Image Classification

https://www.kaggle.com/datasets/samuelcortinhas/cats-and-dogs-image-classification

Explaination:

The Cats and Dogs Image Classification Dataset is designed to train a machine learning model to distinguish between images of cats and dogs. It contains over 1,000 JPEG images scraped from Google Images, with varying resolutions from 100×100 to 2000×1000 pixels. Duplicates have been removed to ensure diversity in the dataset. The objective is to build an accurate classifier that can automatically identify whether an image contains a cat or a dog, a fundamental task in computer vision. The challenge lies in the variability of image quality, lighting, and angles, as well as the visual similarities between cats and dogs, making classification complex.
The goal is to build a Convolutional Neural Network (CNN) that classifies images into two categories: Cats and Dogs. This is a binary image classification problem where the input is an image, and the output is either a label “Cat” or “Dog”.
"""

import kagglehub

path = kagglehub.dataset_download("samuelcortinhas/cats-and-dogs-image-classification")

print("Path to dataset files:", path)

import os
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import KFold
from tensorflow.keras.preprocessing import image

base_dir = "/root/.cache/kagglehub/datasets/samuelcortinhas/cats-and-dogs-image-classification/versions/4"

img_height, img_width = 150, 150
batch_size = 32

datagen = ImageDataGenerator(
    rescale=1.0/255,
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.2
)

train_generator = datagen.flow_from_directory(
    base_dir + '/train',
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='binary',
    subset='training'
)

val_generator = datagen.flow_from_directory(
    base_dir + '/train',
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='binary',
    subset='validation'
)

from google.colab import drive
drive.mount('/content/drive')

import os
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
def create_transfer_model():
    base_model = MobileNetV2(input_shape=(img_height, img_width, 3),
                              include_top=False,
                              weights='imagenet')
    base_model.trainable = False  # Freeze base layers

    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(128, activation='relu')(x)
    x = Dropout(0.5)(x)
    output = Dense(1, activation='sigmoid')(x)

    model = Model(inputs=base_model.input, outputs=output)
    model.compile(optimizer=Adam(learning_rate=0.0001),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model

model = create_transfer_model()
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=10,
    callbacks=[early_stop]
)

plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title("Training and Validation Accuracy")
plt.show()

model.save('cat-dog_model.h5', save_format='h5')